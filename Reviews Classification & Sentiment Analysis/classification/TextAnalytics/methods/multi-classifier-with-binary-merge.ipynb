{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\data_553\\project\\REJ_data\\REJ_data\n"
     ]
    }
   ],
   "source": [
    "%cd F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\data_553\\project\\REJ_data\\REJ_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/l/ReviewClassifier4J/ReviewClassifier4J/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from all.json\n",
    "with open('all.json', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    #alljson=json_data[0:400]\n",
    "df=pd.DataFrame.from_dict(json_normalize(json_data), orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\data_553\\project\\ReviewClassifier4J\\ReviewClassifier4J\\data\n"
     ]
    }
   ],
   "source": [
    "%cd F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\data_553\\project\\ReviewClassifier4J\\ReviewClassifier4J\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug data\n",
    "with open('Bug_tt.json', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    #alljson=json_data[0:400]\n",
    "df_bug=pd.DataFrame.from_dict(json_normalize(json_data), orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug report data\n",
    "with open('Feature_tt.json', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    #alljson=json_data[0:400]\n",
    "df_feature=pd.DataFrame.from_dict(json_normalize(json_data), orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature data\n",
    "with open('Rating_tt.json', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    #alljson=json_data[0:400]\n",
    "df_rating=pd.DataFrame.from_dict(json_normalize(json_data), orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug report data\n",
    "with open('UserExperience_tt.json', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    #alljson=json_data[0:400]\n",
    "df_user_experience = pd.DataFrame.from_dict(json_normalize(json_data), orient='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganize Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/l/ReviewClassifier4J/ReviewClassifier4J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "import pandas as pd\n",
    "p=pd.read_csv(\"data/dataset3_with_nlp_techniques.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled=pd.read_csv(\"data/labelled.csv\")\n",
    "p[\"label\"]= labelled[\"label\"]\n",
    "p.columns.values[0] = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_str_in_list(s): return ' '.join([str(elem) for elem in s])\n",
    "new_comment_list = []\n",
    "for row in p.itertuples():\n",
    "    each_text = getattr(row, \"stopword\")\n",
    "    index = int(getattr(row, \"index\"))\n",
    "    # get all non-english reviews rows\n",
    "    final_value = append_str_in_list(ast.literal_eval(each_text) )\n",
    "    new_comment_list.append(final_value)\n",
    "p['stopwords_removal'] = new_comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_str_in_list(s): return ' '.join([str(elem) for elem in s])\n",
    "new_comment_list = []\n",
    "for row in p.itertuples():\n",
    "    each_text = getattr(row, \"lemmatizer\")\n",
    "    index = int(getattr(row, \"index\"))\n",
    "    # get all non-english reviews rows\n",
    "    final_value = append_str_in_list(ast.literal_eval(each_text) )\n",
    "    new_comment_list.append(final_value)\n",
    "p['lemmatized_comment'] = new_comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words and lemmatize\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lem_text=[str(lemmatizer.lemmatize(i)) for i in word_tokens]\n",
    "    return lem_text\n",
    "p['stopwords_removal_lemmatization']=p['stopwords_removal'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_str_in_list(s): return ' '.join([str(elem) for elem in s])\n",
    "new_comment_list = []\n",
    "for row in p.itertuples():\n",
    "    each_text = getattr(row, \"stopwords_removal_lemmatization\")\n",
    "    index = int(getattr(row, \"index\"))\n",
    "    # get all non-english reviews rows\n",
    "    final_value = append_str_in_list((each_text) )\n",
    "    new_comment_list.append(final_value)\n",
    "p['stopwords_removal_lemmatization'] = new_comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"comment\"] = p[\"processed_text\"]\n",
    "df[\"rating\"] = p[\"score\"]\n",
    "df[\"past\"] = p[\"past\"]\n",
    "df[\"stopwords_removal\"] = p[\"stopwords_removal\"]\n",
    "df[\"reviewer\"] = None\n",
    "df[\"id\"] = None\n",
    "df[\"stemmed\"] = p[\"stemmer\"]\n",
    "df[\"fee\"] = None\n",
    "df[\"title\"] = None\n",
    "df[\"label\"]=p[\"label\"]\n",
    "df[\"future\"] = p[\"future\"]\n",
    "df[\"lemmatized_comment\"] = p[\"lemmatized_comment\"]\n",
    "df[\"sentiScore\"] = None\n",
    "df[\"sentiScore_neg\"] = None\n",
    "df[\"reviewId\"] = None\n",
    "df[\"stopwords_removal_nltk\"] = p[\"stopwords_removal\"]\n",
    "df[\"present_simple\"] = p[\"present_simple\"]\n",
    "df[\"dataSource\"] = None\n",
    "df[\"appId\"] = None\n",
    "df[\"date\"] = p[\"date_ex\"]\n",
    "df[\"sentiScore_pos\"] = None\n",
    "df[\"present_con\"] = p[\"present_con\"]\n",
    "df[\"length_words\"] = p[\"wordcount\"]\n",
    "df[\"stopwords_removal_lemmatization\"] = p[\"stopwords_removal_lemmatization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\553project\n"
     ]
    }
   ],
   "source": [
    "%cd F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\553project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(r'./test_all_new.json',orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split testing data to 4 binary category files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "new_bug_list =[]\n",
    "for row in df1.itertuples():\n",
    "    bug = getattr(row, \"label\")\n",
    "    if(bug != \"Bug\"):\n",
    "        final_value = \"Not_Bug\"\n",
    "    else:\n",
    "        final_value = \"Bug\"\n",
    "    new_bug_list.append(final_value)\n",
    "df1['label'] = new_bug_list\n",
    "df1.to_json(r'./Bug.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "new_feature_list =[]\n",
    "for row in df2.itertuples():\n",
    "    bug = getattr(row, \"label\")\n",
    "    if(bug != \"Feature\"):\n",
    "        final_value = \"Not_Feature\"\n",
    "    else:\n",
    "        final_value = \"Feature\"\n",
    "    new_feature_list.append(final_value)\n",
    "df2['label'] = new_feature_list\n",
    "df2.to_json(r'./Feature.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "new_Rating_list =[]\n",
    "for row in df3.itertuples():\n",
    "    bug = getattr(row, \"label\")\n",
    "    if(bug != \"Rating\"):\n",
    "        final_value = \"Not_Rating\"\n",
    "    else:\n",
    "        final_value = \"Rating\"\n",
    "    new_Rating_list.append(final_value)\n",
    "df3['label'] = new_Rating_list\n",
    "df3.to_json(r'./Rating.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.copy()\n",
    "new_UserExperience_list =[]\n",
    "for row in df4.itertuples():\n",
    "    bug = getattr(row, \"label\")\n",
    "    if(bug != \"UserExperience\"):\n",
    "        final_value = \"Not_UserExperience\"\n",
    "    else:\n",
    "        final_value = \"UserExperience\"\n",
    "    new_UserExperience_list.append(final_value)\n",
    "df4['label'] = new_UserExperience_list\n",
    "df4.to_json(r'./UserExperience.json',orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Testing To Origninal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\553project\\data\n"
     ]
    }
   ],
   "source": [
    "%cd F:\\UBC_Okanagan\\Courses\\DATA 553 Privacy, Security, and Professional Ethics\\553project\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_bug = pd.concat([df_bug, df1], sort=False)\n",
    "df_new_feature = pd.concat([df_feature, df2], sort=False)\n",
    "df_new_rating = pd.concat([df_rating, df3], sort=False)\n",
    "df_new_user_experience = pd.concat([df_user_experience, df4], sort=False)\n",
    "\n",
    "df_new_bug.to_json(r'./Bug_tt.json',orient='records')\n",
    "df_new_feature.to_json(r'./Feature_tt.json',orient='records')\n",
    "df_new_rating.to_json(r'./Rating_tt.json',orient='records')\n",
    "df_new_user_experience.to_json(r'./UserExperience_tt.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
