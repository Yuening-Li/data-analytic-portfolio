{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('REJ_data/all.json', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    #alljson=json_data[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>fee</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>dataSource</th>\n",
       "      <th>appId</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>present_con</th>\n",
       "      <th>length_words</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>Exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Besides the occasional crash, this is an amazi...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>besides occasional crash, this amazing product...</td>\n",
       "      <td>None</td>\n",
       "      <td>264</td>\n",
       "      <td>besid the occa crash, thi is an amaz produc wi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Almost perfect</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>besides occasional crash, amazing product tons...</td>\n",
       "      <td>2</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>besides occasional crash, this amaze product w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>This could be a great app if it was predictabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>this could be great app if was predictable, bu...</td>\n",
       "      <td>None</td>\n",
       "      <td>111</td>\n",
       "      <td>thi could be a gre ap if it was predictable, b...</td>\n",
       "      <td>None</td>\n",
       "      <td>Take a photo of your boarding pass</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>could great app predictable, full bugs unpredi...</td>\n",
       "      <td>9</td>\n",
       "      <td>AppStore_Random</td>\n",
       "      <td>382698565</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>this could be great app if be predictable, but...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I can't open since the last 2 updates Pop-ups ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>can't open since last 2 updates pop-ups go cra...</td>\n",
       "      <td>None</td>\n",
       "      <td>210</td>\n",
       "      <td>i can't op sint the last 2 upd pop-ups go craz...</td>\n",
       "      <td>None</td>\n",
       "      <td>Won't open due to pop-ups since upgrade</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>can't open since last 2 updates pop-ups go cra...</td>\n",
       "      <td>1</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>can't open since last 2 update pop-up go crazy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rating  past  \\\n",
       "0  Besides the occasional crash, this is an amazi...       5     0   \n",
       "1  This could be a great app if it was predictabl...       1     1   \n",
       "2  I can't open since the last 2 updates Pop-ups ...       1     0   \n",
       "\n",
       "                                   stopwords_removal reviewer   id  \\\n",
       "0  besides occasional crash, this amazing product...     None  264   \n",
       "1  this could be great app if was predictable, bu...     None  111   \n",
       "2  can't open since last 2 updates pop-ups go cra...     None  210   \n",
       "\n",
       "                                             stemmed   fee  \\\n",
       "0  besid the occa crash, thi is an amaz produc wi...  None   \n",
       "1  thi could be a gre ap if it was predictable, b...  None   \n",
       "2  i can't op sint the last 2 upd pop-ups go craz...  None   \n",
       "\n",
       "                                     title label  ...  \\\n",
       "0                           Almost perfect   Bug  ...   \n",
       "1       Take a photo of your boarding pass   Bug  ...   \n",
       "2  Won't open due to pop-ups since upgrade   Bug  ...   \n",
       "\n",
       "                              stopwords_removal_nltk present_simple  \\\n",
       "0  besides occasional crash, amazing product tons...              2   \n",
       "1  could great app predictable, full bugs unpredi...              9   \n",
       "2  can't open since last 2 updates pop-ups go cra...              1   \n",
       "\n",
       "                       dataSource      appId  date sentiScore_pos  \\\n",
       "0  RE2014_app_and_play_store_apps       None  None              3   \n",
       "1                 AppStore_Random  382698565  None              3   \n",
       "2  RE2014_app_and_play_store_apps       None  None              2   \n",
       "\n",
       "   present_con length_words  \\\n",
       "0            1           22   \n",
       "1            0           58   \n",
       "2            1           24   \n",
       "\n",
       "                     stopwords_removal_lemmatization Exclude  \n",
       "0  besides occasional crash, this amaze product w...     NaN  \n",
       "1  this could be great app if be predictable, but...     NaN  \n",
       "2  can't open since last 2 update pop-up go crazy...     NaN  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame.from_dict(json_normalize(json_data), orient='columns')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>fee</th>\n",
       "      <th>title</th>\n",
       "      <th>future</th>\n",
       "      <th>...</th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>dataSource</th>\n",
       "      <th>appId</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>present_con</th>\n",
       "      <th>length_words</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>Exclude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Bug</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>27</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>27</td>\n",
       "      <td>343</td>\n",
       "      <td>370</td>\n",
       "      <td>...</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>136</td>\n",
       "      <td>27</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Feature</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>135</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>135</td>\n",
       "      <td>117</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>179</td>\n",
       "      <td>135</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Rating</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>456</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>456</td>\n",
       "      <td>2006</td>\n",
       "      <td>2462</td>\n",
       "      <td>...</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>1176</td>\n",
       "      <td>456</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "      <td>2462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UserExperience</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>16</td>\n",
       "      <td>591</td>\n",
       "      <td>607</td>\n",
       "      <td>...</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>259</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                comment  rating  past  stopwords_removal  reviewer    id  \\\n",
       "label                                                                      \n",
       "Bug                 370     370   370                370        27   370   \n",
       "Feature             252     252   252                252       135   252   \n",
       "Rating             2462    2462  2462               2462       456  2462   \n",
       "UserExperience      607     607   607                607        16   607   \n",
       "\n",
       "                stemmed  fee  title  future  ...  stopwords_removal_nltk  \\\n",
       "label                                        ...                           \n",
       "Bug                 370   27    343     370  ...                     370   \n",
       "Feature             252  135    117     252  ...                     252   \n",
       "Rating             2462  456   2006    2462  ...                    2462   \n",
       "UserExperience      607   16    591     607  ...                     607   \n",
       "\n",
       "                present_simple  dataSource  appId  date  sentiScore_pos  \\\n",
       "label                                                                     \n",
       "Bug                        370         370    136    27             370   \n",
       "Feature                    252         252    179   135             252   \n",
       "Rating                    2462        2462   1176   456            2462   \n",
       "UserExperience             607         607    259    16             607   \n",
       "\n",
       "                present_con  length_words  stopwords_removal_lemmatization  \\\n",
       "label                                                                        \n",
       "Bug                     370           370                              370   \n",
       "Feature                 252           252                              252   \n",
       "Rating                 2462          2462                             2462   \n",
       "UserExperience          607           607                              607   \n",
       "\n",
       "                Exclude  \n",
       "label                    \n",
       "Bug                   0  \n",
       "Feature             252  \n",
       "Rating             2462  \n",
       "UserExperience      607  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=pd.read_csv('FinalProcessed.csv')\n",
    "# p.drop('text',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample size was determined by using the following website:https://www.surveysystem.com/sscalce.htm\n",
    "# import random\n",
    "# test=p.sample(384)\n",
    "# test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('Dataset3.csv', index=None) #exported for labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appTitle</th>\n",
       "      <th>userName</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>Category</th>\n",
       "      <th>date_ex</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Helix Jump</td>\n",
       "      <td>wan husna</td>\n",
       "      <td>April 14, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>GAME_ACTION</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>A great game to be during times  Nice</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pandora Music</td>\n",
       "      <td>taja sims</td>\n",
       "      <td>March 13, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>MUSIC_AND_AUDIO</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>I truly love pandora</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lose Belly Fat in 30 Days - Flat Stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>December 15, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>I need all the help I need 5ft and I need to l...</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Roblox</td>\n",
       "      <td>Reece McBratney</td>\n",
       "      <td>March 24, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>it  s not great but it  s good</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABCmouse.com</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>February 22, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>I think this is cool this is learning and and ...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>Duolingo: Learn Languages Free</td>\n",
       "      <td>Gustavo Salgado</td>\n",
       "      <td>March 25, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Really good for</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>Lose Belly Fat in 30 Days - Flat Stomach</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>March 13, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>It is my first time to use this  see who it is</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>Amazon Prime Video</td>\n",
       "      <td>Hemlata Shahabadi</td>\n",
       "      <td>March 23, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>I love it</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>Helix Jump</td>\n",
       "      <td>R Adkins</td>\n",
       "      <td>March 26, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>GAME_ACTION</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>fun fact it  s fun</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>Roku</td>\n",
       "      <td>Melanie Vargas</td>\n",
       "      <td>March 24, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>I dont stay in and wont work everyday  I love ...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     appTitle           userName  \\\n",
       "0                                  Helix Jump          wan husna   \n",
       "1                               Pandora Music          taja sims   \n",
       "2    Lose Belly Fat in 30 Days - Flat Stomach                NaN   \n",
       "3                                      Roblox    Reece McBratney   \n",
       "4                                ABCmouse.com      A Google User   \n",
       "..                                        ...                ...   \n",
       "379            Duolingo: Learn Languages Free    Gustavo Salgado   \n",
       "380  Lose Belly Fat in 30 Days - Flat Stomach      A Google User   \n",
       "381                        Amazon Prime Video  Hemlata Shahabadi   \n",
       "382                                Helix Jump           R Adkins   \n",
       "383                                      Roku     Melanie Vargas   \n",
       "\n",
       "                  date  score            Category     date_ex  \\\n",
       "0       April 14, 2019      5         GAME_ACTION  2019-04-14   \n",
       "1       March 13, 2019      5     MUSIC_AND_AUDIO  2019-04-01   \n",
       "2    December 15, 2018      5  HEALTH_AND_FITNESS  2019-03-24   \n",
       "3       March 24, 2019      3              FAMILY  2019-03-24   \n",
       "4    February 22, 2018      5           EDUCATION  2019-04-07   \n",
       "..                 ...    ...                 ...         ...   \n",
       "379     March 25, 2019      5           EDUCATION  2019-04-01   \n",
       "380     March 13, 2019      1  HEALTH_AND_FITNESS  2019-04-21   \n",
       "381     March 23, 2019      5       ENTERTAINMENT  2019-03-24   \n",
       "382     March 26, 2019      5         GAME_ACTION  2019-04-01   \n",
       "383     March 24, 2019      2       ENTERTAINMENT  2019-04-14   \n",
       "\n",
       "                                        processed_text  wordcount  \n",
       "0                A great game to be during times  Nice        8.0  \n",
       "1                                 I truly love pandora        4.0  \n",
       "2    I need all the help I need 5ft and I need to l...       28.0  \n",
       "3                       it  s not great but it  s good        8.0  \n",
       "4    I think this is cool this is learning and and ...       13.0  \n",
       "..                                                 ...        ...  \n",
       "379                                   Really good for         3.0  \n",
       "380   It is my first time to use this  see who it is         12.0  \n",
       "381                                          I love it        3.0  \n",
       "382                                 fun fact it  s fun        5.0  \n",
       "383  I dont stay in and wont work everyday  I love ...       19.0  \n",
       "\n",
       "[384 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop=set(stopwords.words('english'))\n",
    "#nltk.download('word_tokenize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appTitle</th>\n",
       "      <th>userName</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>Category</th>\n",
       "      <th>date_ex</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Helix Jump</td>\n",
       "      <td>wan husna</td>\n",
       "      <td>April 14, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>GAME_ACTION</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>A great game to be during times  Nice</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pandora Music</td>\n",
       "      <td>taja sims</td>\n",
       "      <td>March 13, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>MUSIC_AND_AUDIO</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>I truly love pandora</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lose Belly Fat in 30 Days - Flat Stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>December 15, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>I need all the help I need 5ft and I need to l...</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Roblox</td>\n",
       "      <td>Reece McBratney</td>\n",
       "      <td>March 24, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>it  s not great but it  s good</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABCmouse.com</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>February 22, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>I think this is cool this is learning and and ...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   appTitle         userName  \\\n",
       "0                                Helix Jump        wan husna   \n",
       "1                             Pandora Music        taja sims   \n",
       "2  Lose Belly Fat in 30 Days - Flat Stomach              NaN   \n",
       "3                                    Roblox  Reece McBratney   \n",
       "4                              ABCmouse.com    A Google User   \n",
       "\n",
       "                date  score            Category     date_ex  \\\n",
       "0     April 14, 2019      5         GAME_ACTION  2019-04-14   \n",
       "1     March 13, 2019      5     MUSIC_AND_AUDIO  2019-04-01   \n",
       "2  December 15, 2018      5  HEALTH_AND_FITNESS  2019-03-24   \n",
       "3     March 24, 2019      3              FAMILY  2019-03-24   \n",
       "4  February 22, 2018      5           EDUCATION  2019-04-07   \n",
       "\n",
       "                                      processed_text  wordcount  \n",
       "0              A great game to be during times  Nice        8.0  \n",
       "1                               I truly love pandora        4.0  \n",
       "2  I need all the help I need 5ft and I need to l...       28.0  \n",
       "3                     it  s not great but it  s good        8.0  \n",
       "4  I think this is cool this is learning and and ...       13.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dataset3.csv\")\n",
    "#df.drop('label',axis=1,inplace=True)\n",
    "df['stopword']= df['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopword']=df['stopword'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stopw=set(stopwords.words('english'))\n",
    "    words=[w for w in word_tokens if w not in stopw]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['stopword'].str.lower()\n",
    "df['stopword']=df['stopword'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appTitle</th>\n",
       "      <th>userName</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>Category</th>\n",
       "      <th>date_ex</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Helix Jump</td>\n",
       "      <td>wan husna</td>\n",
       "      <td>April 14, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>GAME_ACTION</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>A great game to be during times  Nice</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[great, game, times, nice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pandora Music</td>\n",
       "      <td>taja sims</td>\n",
       "      <td>March 13, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>MUSIC_AND_AUDIO</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>I truly love pandora</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[truly, love, pandora]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lose Belly Fat in 30 Days - Flat Stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>December 15, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>I need all the help I need 5ft and I need to l...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[need, help, need, 5ft, need, lose, stomach, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Roblox</td>\n",
       "      <td>Reece McBratney</td>\n",
       "      <td>March 24, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>it  s not great but it  s good</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[great, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABCmouse.com</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>February 22, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>I think this is cool this is learning and and ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[think, cool, learning, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>Duolingo: Learn Languages Free</td>\n",
       "      <td>Gustavo Salgado</td>\n",
       "      <td>March 25, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Really good for</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[really, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>Lose Belly Fat in 30 Days - Flat Stomach</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>March 13, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>It is my first time to use this  see who it is</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[first, time, use, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>Amazon Prime Video</td>\n",
       "      <td>Hemlata Shahabadi</td>\n",
       "      <td>March 23, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>I love it</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>Helix Jump</td>\n",
       "      <td>R Adkins</td>\n",
       "      <td>March 26, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>GAME_ACTION</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>fun fact it  s fun</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[fun, fact, fun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>Roku</td>\n",
       "      <td>Melanie Vargas</td>\n",
       "      <td>March 24, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>I dont stay in and wont work everyday  I love ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[dont, stay, wont, work, everyday, love, phone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     appTitle           userName  \\\n",
       "0                                  Helix Jump          wan husna   \n",
       "1                               Pandora Music          taja sims   \n",
       "2    Lose Belly Fat in 30 Days - Flat Stomach                NaN   \n",
       "3                                      Roblox    Reece McBratney   \n",
       "4                                ABCmouse.com      A Google User   \n",
       "..                                        ...                ...   \n",
       "379            Duolingo: Learn Languages Free    Gustavo Salgado   \n",
       "380  Lose Belly Fat in 30 Days - Flat Stomach      A Google User   \n",
       "381                        Amazon Prime Video  Hemlata Shahabadi   \n",
       "382                                Helix Jump           R Adkins   \n",
       "383                                      Roku     Melanie Vargas   \n",
       "\n",
       "                  date  score            Category     date_ex  \\\n",
       "0       April 14, 2019      5         GAME_ACTION  2019-04-14   \n",
       "1       March 13, 2019      5     MUSIC_AND_AUDIO  2019-04-01   \n",
       "2    December 15, 2018      5  HEALTH_AND_FITNESS  2019-03-24   \n",
       "3       March 24, 2019      3              FAMILY  2019-03-24   \n",
       "4    February 22, 2018      5           EDUCATION  2019-04-07   \n",
       "..                 ...    ...                 ...         ...   \n",
       "379     March 25, 2019      5           EDUCATION  2019-04-01   \n",
       "380     March 13, 2019      1  HEALTH_AND_FITNESS  2019-04-21   \n",
       "381     March 23, 2019      5       ENTERTAINMENT  2019-03-24   \n",
       "382     March 26, 2019      5         GAME_ACTION  2019-04-01   \n",
       "383     March 24, 2019      2       ENTERTAINMENT  2019-04-14   \n",
       "\n",
       "                                        processed_text  wordcount  \\\n",
       "0                A great game to be during times  Nice        8.0   \n",
       "1                                 I truly love pandora        4.0   \n",
       "2    I need all the help I need 5ft and I need to l...       28.0   \n",
       "3                       it  s not great but it  s good        8.0   \n",
       "4    I think this is cool this is learning and and ...       13.0   \n",
       "..                                                 ...        ...   \n",
       "379                                   Really good for         3.0   \n",
       "380   It is my first time to use this  see who it is         12.0   \n",
       "381                                          I love it        3.0   \n",
       "382                                 fun fact it  s fun        5.0   \n",
       "383  I dont stay in and wont work everyday  I love ...       19.0   \n",
       "\n",
       "                                              stopword  \n",
       "0                           [great, game, times, nice]  \n",
       "1                               [truly, love, pandora]  \n",
       "2    [need, help, need, 5ft, need, lose, stomach, h...  \n",
       "3                                        [great, good]  \n",
       "4                        [think, cool, learning, love]  \n",
       "..                                                 ...  \n",
       "379                                     [really, good]  \n",
       "380                            [first, time, use, see]  \n",
       "381                                             [love]  \n",
       "382                                   [fun, fact, fun]  \n",
       "383  [dont, stay, wont, work, everyday, love, phone...  \n",
       "\n",
       "[384 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatizer']=df['processed_text']\n",
    "df['lemmatizer']=df['lemmatizer'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/kt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lem_text=[lemmatizer.lemmatize(i) for i in word_tokens]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatizer']=df['lemmatizer'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "def word_stemmer(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stem_text= \" \".join([stemmer.stem(i) for i in word_tokens])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmer']=df['processed_text']\n",
    "df['stemmer']=df['stemmer'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmer']=df['stemmer'].apply(lambda x: word_stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      a great game to be dure time nice\n",
       "1                                   i truli love pandora\n",
       "2      i need all the help i need 5ft and i need to l...\n",
       "3                           it s not great but it s good\n",
       "4      i think thi is cool thi is learn and and i lov...\n",
       "                             ...                        \n",
       "379                                      realli good for\n",
       "380         it is my first time to use thi see who it is\n",
       "381                                            i love it\n",
       "382                                    fun fact it s fun\n",
       "383    i dont stay in and wont work everyday i love h...\n",
       "Name: stemmer, Length: 384, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemmer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('stmmer',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bigrams']=df['processed_text']\n",
    "df['bigrams']=df['bigrams'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]\n",
    "for line in df['bigrams']:\n",
    "    token = nltk.word_tokenize(line)\n",
    "    bigram = list(ngrams(token, 2))\n",
    "    b.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bigrams']=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appTitle</th>\n",
       "      <th>userName</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>Category</th>\n",
       "      <th>date_ex</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>stopword</th>\n",
       "      <th>lemmatizer</th>\n",
       "      <th>stemmer</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Helix Jump</td>\n",
       "      <td>wan husna</td>\n",
       "      <td>April 14, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>GAME_ACTION</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>A great game to be during times  Nice</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[great, game, times, nice]</td>\n",
       "      <td>[a, great, game, to, be, during, time, nice]</td>\n",
       "      <td>a great game to be dure time nice</td>\n",
       "      <td>[(a, great), (great, game), (game, to), (to, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pandora Music</td>\n",
       "      <td>taja sims</td>\n",
       "      <td>March 13, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>MUSIC_AND_AUDIO</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>I truly love pandora</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[truly, love, pandora]</td>\n",
       "      <td>[i, truly, love, pandora]</td>\n",
       "      <td>i truli love pandora</td>\n",
       "      <td>[(i, truly), (truly, love), (love, pandora)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lose Belly Fat in 30 Days - Flat Stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>December 15, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>I need all the help I need 5ft and I need to l...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[need, help, need, 5ft, need, lose, stomach, h...</td>\n",
       "      <td>[i, need, all, the, help, i, need, 5ft, and, i...</td>\n",
       "      <td>i need all the help i need 5ft and i need to l...</td>\n",
       "      <td>[(i, need), (need, all), (all, the), (the, hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Roblox</td>\n",
       "      <td>Reece McBratney</td>\n",
       "      <td>March 24, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>it  s not great but it  s good</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[great, good]</td>\n",
       "      <td>[it, s, not, great, but, it, s, good]</td>\n",
       "      <td>it s not great but it s good</td>\n",
       "      <td>[(it, s), (s, not), (not, great), (great, but)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABCmouse.com</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>February 22, 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>I think this is cool this is learning and and ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[think, cool, learning, love]</td>\n",
       "      <td>[i, think, this, is, cool, this, is, learning,...</td>\n",
       "      <td>i think thi is cool thi is learn and and i lov...</td>\n",
       "      <td>[(i, think), (think, this), (this, is), (is, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   appTitle         userName  \\\n",
       "0                                Helix Jump        wan husna   \n",
       "1                             Pandora Music        taja sims   \n",
       "2  Lose Belly Fat in 30 Days - Flat Stomach              NaN   \n",
       "3                                    Roblox  Reece McBratney   \n",
       "4                              ABCmouse.com    A Google User   \n",
       "\n",
       "                date  score            Category     date_ex  \\\n",
       "0     April 14, 2019      5         GAME_ACTION  2019-04-14   \n",
       "1     March 13, 2019      5     MUSIC_AND_AUDIO  2019-04-01   \n",
       "2  December 15, 2018      5  HEALTH_AND_FITNESS  2019-03-24   \n",
       "3     March 24, 2019      3              FAMILY  2019-03-24   \n",
       "4  February 22, 2018      5           EDUCATION  2019-04-07   \n",
       "\n",
       "                                      processed_text  wordcount  \\\n",
       "0              A great game to be during times  Nice        8.0   \n",
       "1                               I truly love pandora        4.0   \n",
       "2  I need all the help I need 5ft and I need to l...       28.0   \n",
       "3                     it  s not great but it  s good        8.0   \n",
       "4  I think this is cool this is learning and and ...       13.0   \n",
       "\n",
       "                                            stopword  \\\n",
       "0                         [great, game, times, nice]   \n",
       "1                             [truly, love, pandora]   \n",
       "2  [need, help, need, 5ft, need, lose, stomach, h...   \n",
       "3                                      [great, good]   \n",
       "4                      [think, cool, learning, love]   \n",
       "\n",
       "                                          lemmatizer  \\\n",
       "0       [a, great, game, to, be, during, time, nice]   \n",
       "1                          [i, truly, love, pandora]   \n",
       "2  [i, need, all, the, help, i, need, 5ft, and, i...   \n",
       "3              [it, s, not, great, but, it, s, good]   \n",
       "4  [i, think, this, is, cool, this, is, learning,...   \n",
       "\n",
       "                                             stemmer  \\\n",
       "0                  a great game to be dure time nice   \n",
       "1                               i truli love pandora   \n",
       "2  i need all the help i need 5ft and i need to l...   \n",
       "3                       it s not great but it s good   \n",
       "4  i think thi is cool thi is learn and and i lov...   \n",
       "\n",
       "                                             bigrams  \n",
       "0  [(a, great), (great, game), (game, to), (to, b...  \n",
       "1       [(i, truly), (truly, love), (love, pandora)]  \n",
       "2  [(i, need), (need, all), (all, the), (the, hel...  \n",
       "3  [(it, s), (s, not), (not, great), (great, but)...  \n",
       "4  [(i, think), (think, this), (this, is), (is, c...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bow']=df['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "bow = vectorizer.fit_transform(df.processed_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 125,\n",
       " 'great': 41,\n",
       " 'game': 50,\n",
       " 'to': 218,\n",
       " 'be': 30,\n",
       " 'during': 3,\n",
       " 'times': 6,\n",
       " 'nice': 9,\n",
       " 'i': 271,\n",
       " 'truly': 1,\n",
       " 'love': 58,\n",
       " 'pandora': 3,\n",
       " 'need': 22,\n",
       " 'all': 24,\n",
       " 'the': 198,\n",
       " 'help': 5,\n",
       " '5ft': 1,\n",
       " 'and': 148,\n",
       " 'lose': 3,\n",
       " 'my': 85,\n",
       " 'stomach': 1,\n",
       " 'for': 80,\n",
       " 'hip': 1,\n",
       " 'new': 9,\n",
       " 'one': 19,\n",
       " 'so': 43,\n",
       " 'weight': 2,\n",
       " 'goff': 1,\n",
       " 'it': 236,\n",
       " 's': 45,\n",
       " 'not': 43,\n",
       " 'but': 70,\n",
       " 'good': 58,\n",
       " 'think': 7,\n",
       " 'this': 115,\n",
       " 'is': 142,\n",
       " 'cool': 9,\n",
       " 'learning': 5,\n",
       " 'that': 55,\n",
       " 'was': 18,\n",
       " 'awesome': 14,\n",
       " 'sorry': 2,\n",
       " 'say': 5,\n",
       " 'get': 21,\n",
       " 'busy': 1,\n",
       " 'drink': 3,\n",
       " 'water': 6,\n",
       " 'don': 15,\n",
       " 't': 49,\n",
       " 'want': 10,\n",
       " 'give': 6,\n",
       " 'even': 11,\n",
       " '1': 7,\n",
       " 'star': 3,\n",
       " 'fraud': 1,\n",
       " 'request': 1,\n",
       " 'use': 50,\n",
       " 'after': 13,\n",
       " 'showing': 2,\n",
       " 'subscribe': 1,\n",
       " 'unlock': 1,\n",
       " 'unsubscribing': 1,\n",
       " 'they': 18,\n",
       " 'though': 1,\n",
       " 'superb': 2,\n",
       " 'around': 2,\n",
       " 'your': 27,\n",
       " 'bar': 1,\n",
       " 'code': 1,\n",
       " 'feature': 3,\n",
       " 'work': 16,\n",
       " 'properly': 1,\n",
       " 'won': 7,\n",
       " 'take': 7,\n",
       " 'me': 39,\n",
       " 'where': 5,\n",
       " 'can': 35,\n",
       " 'see': 12,\n",
       " 'food': 6,\n",
       " 'in': 47,\n",
       " 'view': 2,\n",
       " 'finder': 1,\n",
       " 'fix': 11,\n",
       " 'amazing': 7,\n",
       " 'cant': 2,\n",
       " 'then': 10,\n",
       " 'any': 10,\n",
       " 'daughter': 1,\n",
       " '4y': 1,\n",
       " 'o': 1,\n",
       " 'much': 15,\n",
       " 'tell': 3,\n",
       " 'she': 1,\n",
       " 'lot': 9,\n",
       " 'more': 16,\n",
       " 'however': 5,\n",
       " 'on': 44,\n",
       " '3': 7,\n",
       " 'now': 13,\n",
       " 'cause': 5,\n",
       " 'pay': 14,\n",
       " 'premium': 10,\n",
       " 'should': 8,\n",
       " 'able': 4,\n",
       " 'listen': 5,\n",
       " 'anything': 3,\n",
       " 'certain': 1,\n",
       " 'artist': 1,\n",
       " 'at': 16,\n",
       " 'least': 2,\n",
       " 'once': 3,\n",
       " 'month': 2,\n",
       " 'total': 3,\n",
       " 'time': 26,\n",
       " 'killer': 1,\n",
       " 'really': 31,\n",
       " 'fun': 20,\n",
       " 'we': 7,\n",
       " 'terrible': 2,\n",
       " 'went': 1,\n",
       " 'running': 3,\n",
       " 'count': 1,\n",
       " 'single': 5,\n",
       " 'step': 2,\n",
       " 'excellent': 5,\n",
       " 'thanks': 9,\n",
       " 'very': 42,\n",
       " 'spend': 2,\n",
       " 'hour': 3,\n",
       " 'do': 11,\n",
       " 'update': 11,\n",
       " 'keep': 12,\n",
       " 'older': 2,\n",
       " 'version': 7,\n",
       " 'wish': 8,\n",
       " 'saw': 2,\n",
       " 'about': 7,\n",
       " 'first': 6,\n",
       " 'didnt': 1,\n",
       " 'look': 1,\n",
       " 'like': 29,\n",
       " 'many': 8,\n",
       " 'am': 8,\n",
       " 'getting': 9,\n",
       " 'from': 9,\n",
       " 'none': 1,\n",
       " 'of': 68,\n",
       " 'an': 10,\n",
       " 'issue': 7,\n",
       " 'before': 8,\n",
       " 'working': 7,\n",
       " 'error': 1,\n",
       " 'coming': 1,\n",
       " 'up': 27,\n",
       " '20': 3,\n",
       " 'day': 9,\n",
       " 'just': 26,\n",
       " 'sending': 1,\n",
       " 'log': 6,\n",
       " 'dev': 1,\n",
       " 'uninstalled': 1,\n",
       " 'still': 12,\n",
       " 'no': 15,\n",
       " 'luck': 2,\n",
       " 'old': 5,\n",
       " 'android': 5,\n",
       " '8': 1,\n",
       " '0': 3,\n",
       " 'v20': 1,\n",
       " 'other': 16,\n",
       " 'too': 12,\n",
       " 'there': 9,\n",
       " 'have': 61,\n",
       " 'helping': 3,\n",
       " 'study': 2,\n",
       " 'succeed': 1,\n",
       " 'money': 10,\n",
       " 'result': 2,\n",
       " 'con': 2,\n",
       " 'heart': 1,\n",
       " 'pleasing': 1,\n",
       " 'yeah': 2,\n",
       " 'job': 2,\n",
       " 'far': 5,\n",
       " 'easier': 2,\n",
       " 'got': 10,\n",
       " '1099': 1,\n",
       " 'year': 3,\n",
       " '119': 1,\n",
       " 'file': 4,\n",
       " 'if': 21,\n",
       " 'you': 70,\n",
       " 're': 4,\n",
       " 'self': 1,\n",
       " 'employed': 1,\n",
       " 'hate': 7,\n",
       " 'his': 2,\n",
       " 'simple': 3,\n",
       " 'easy': 25,\n",
       " 'only': 9,\n",
       " 'thing': 7,\n",
       " 'could': 12,\n",
       " 'making': 3,\n",
       " 'sure': 4,\n",
       " 'user': 2,\n",
       " 'swipe': 2,\n",
       " 'right': 3,\n",
       " 'next': 1,\n",
       " 'page': 4,\n",
       " 'works': 7,\n",
       " 'well': 6,\n",
       " 'with': 38,\n",
       " '9': 1,\n",
       " 'pie': 2,\n",
       " 'quick': 4,\n",
       " 'process': 1,\n",
       " 'track': 5,\n",
       " 'calorie': 1,\n",
       " 'also': 8,\n",
       " 'diary': 1,\n",
       " 'how': 8,\n",
       " 'weigh': 1,\n",
       " 'dont': 6,\n",
       " 'drive': 1,\n",
       " 'deposit': 1,\n",
       " 'line': 2,\n",
       " 'bill': 3,\n",
       " 'displayed': 1,\n",
       " 'clearly': 3,\n",
       " 'left': 2,\n",
       " 'alone': 2,\n",
       " 'useless': 4,\n",
       " 'person': 3,\n",
       " 'check': 2,\n",
       " 'ever': 9,\n",
       " 'are': 24,\n",
       " 'their': 4,\n",
       " 'location': 1,\n",
       " 'purpose': 1,\n",
       " 'tried': 5,\n",
       " 'filing': 1,\n",
       " 'turbo': 2,\n",
       " 'tax': 2,\n",
       " 'because': 9,\n",
       " 'know': 9,\n",
       " '2017': 2,\n",
       " 'ask': 1,\n",
       " 'verify': 1,\n",
       " 'identity': 1,\n",
       " 'loan': 1,\n",
       " 'or': 15,\n",
       " 'credit': 10,\n",
       " 'card': 6,\n",
       " 'number': 3,\n",
       " 'which': 4,\n",
       " 'hope': 3,\n",
       " 'charge': 3,\n",
       " 'especially': 4,\n",
       " 'extra': 1,\n",
       " 'had': 15,\n",
       " 'instead': 4,\n",
       " 'going': 5,\n",
       " 'them': 6,\n",
       " 'done': 4,\n",
       " 'everything': 4,\n",
       " 'expensive': 1,\n",
       " 'paying': 1,\n",
       " 'cute': 1,\n",
       " 'rate': 3,\n",
       " 'five': 1,\n",
       " 'listening': 3,\n",
       " 'local': 1,\n",
       " 'radio': 1,\n",
       " 'here': 3,\n",
       " 'question': 1,\n",
       " 'delete': 3,\n",
       " 'hulu': 4,\n",
       " 'later': 2,\n",
       " 'put': 4,\n",
       " 'account': 6,\n",
       " 'back': 6,\n",
       " 'forgot': 1,\n",
       " 'password': 7,\n",
       " 'when': 24,\n",
       " 'payment': 3,\n",
       " 'each': 5,\n",
       " 'will': 18,\n",
       " 'stay': 3,\n",
       " 'please': 15,\n",
       " 'doesnt': 3,\n",
       " 'way': 14,\n",
       " 'cancel': 1,\n",
       " 'member': 1,\n",
       " 'ship': 1,\n",
       " 'pause': 1,\n",
       " 'music': 20,\n",
       " 'actually': 2,\n",
       " 'sad': 1,\n",
       " 'provider': 1,\n",
       " 'most': 6,\n",
       " 'locked': 3,\n",
       " 'hard': 5,\n",
       " 'change': 5,\n",
       " 'make': 10,\n",
       " 'own': 3,\n",
       " 'world': 3,\n",
       " 'class': 2,\n",
       " 'support': 5,\n",
       " 'delighted': 1,\n",
       " 'life': 4,\n",
       " 'saver': 1,\n",
       " 'convenient': 2,\n",
       " 'worst': 3,\n",
       " 'waste': 3,\n",
       " 'playback': 1,\n",
       " 'phone': 13,\n",
       " 'screen': 4,\n",
       " 'stop': 2,\n",
       " '5': 7,\n",
       " '10': 3,\n",
       " 'such': 1,\n",
       " 'problem': 5,\n",
       " 'quite': 1,\n",
       " 'play': 12,\n",
       " 'starting': 2,\n",
       " 'than': 14,\n",
       " 'u': 8,\n",
       " 'easily': 2,\n",
       " 'useful': 5,\n",
       " 'needs': 4,\n",
       " 'care': 2,\n",
       " 'experience': 3,\n",
       " 'reliable': 1,\n",
       " 'super': 2,\n",
       " 'helpful': 5,\n",
       " 'broke': 2,\n",
       " 'evening': 1,\n",
       " 'checked': 2,\n",
       " 'again': 4,\n",
       " 'morning': 2,\n",
       " 'same': 5,\n",
       " 'stuff': 3,\n",
       " 'worser': 1,\n",
       " 'either': 1,\n",
       " 'add': 10,\n",
       " 'language': 3,\n",
       " 'absolutely': 1,\n",
       " 'available': 2,\n",
       " 'higher': 1,\n",
       " 'knowledge': 1,\n",
       " 'galaxy': 1,\n",
       " 's7': 1,\n",
       " 'kitchen': 1,\n",
       " 'never': 12,\n",
       " 'what': 11,\n",
       " 'its': 22,\n",
       " 'mathematics': 1,\n",
       " 'dumb': 1,\n",
       " 'low': 1,\n",
       " 'speed': 2,\n",
       " 'content': 3,\n",
       " 'posted': 1,\n",
       " 'by': 7,\n",
       " 'as': 12,\n",
       " 'fast': 4,\n",
       " 'through': 6,\n",
       " 'wa': 1,\n",
       " 'practically': 1,\n",
       " 'every': 10,\n",
       " 'open': 6,\n",
       " 'song': 4,\n",
       " 'stupid': 2,\n",
       " 'ad': 4,\n",
       " 'thats': 2,\n",
       " 'hub': 2,\n",
       " 'shield': 3,\n",
       " 'box': 2,\n",
       " 'biggest': 3,\n",
       " 'interface': 2,\n",
       " 'forced': 1,\n",
       " 'boot': 2,\n",
       " 'something': 3,\n",
       " 'several': 1,\n",
       " 'forever': 1,\n",
       " 'factor': 1,\n",
       " 'independent': 1,\n",
       " 'connected': 2,\n",
       " 'setting': 2,\n",
       " 'better': 7,\n",
       " 'm': 8,\n",
       " 'happy': 4,\n",
       " 'drinking': 1,\n",
       " 'would': 9,\n",
       " 'monitor': 1,\n",
       " 'included': 1,\n",
       " 'level': 1,\n",
       " 's9': 3,\n",
       " 'plus': 5,\n",
       " 'hala': 1,\n",
       " 'tinder': 3,\n",
       " 'v': 2,\n",
       " 'upgrade': 5,\n",
       " 'bit': 2,\n",
       " 'always': 5,\n",
       " 'been': 4,\n",
       " 'fan': 2,\n",
       " 'power': 2,\n",
       " 'alas': 1,\n",
       " 'free': 19,\n",
       " 'trouble': 3,\n",
       " 'sleeping': 1,\n",
       " 'night': 3,\n",
       " 'without': 7,\n",
       " 'off': 3,\n",
       " 'thank': 8,\n",
       " 'pretty': 10,\n",
       " 'wit': 1,\n",
       " 'does': 6,\n",
       " 'target': 1,\n",
       " 'program': 1,\n",
       " 'whether': 2,\n",
       " 'choose': 2,\n",
       " 'learn': 5,\n",
       " 'quiz': 1,\n",
       " 'yourself': 1,\n",
       " 'ability': 1,\n",
       " 'enter': 2,\n",
       " 'main': 2,\n",
       " 'challenge': 1,\n",
       " 'portion': 1,\n",
       " 'control': 2,\n",
       " 'perfect': 3,\n",
       " 'anywhere': 2,\n",
       " 'else': 2,\n",
       " 'large': 1,\n",
       " 'law': 1,\n",
       " 'firm': 1,\n",
       " 'frequently': 2,\n",
       " 'go': 12,\n",
       " 'greatly': 1,\n",
       " 'dealing': 1,\n",
       " 'stress': 1,\n",
       " 'these': 2,\n",
       " 'extremely': 2,\n",
       " 'pass': 1,\n",
       " 'exactly': 1,\n",
       " 'write': 1,\n",
       " 'come': 3,\n",
       " 'straight': 1,\n",
       " 'fake': 1,\n",
       " 'guess': 1,\n",
       " 'freak': 1,\n",
       " 'nowhere': 1,\n",
       " 'near': 1,\n",
       " 'start': 3,\n",
       " 'meditation': 1,\n",
       " 'find': 5,\n",
       " 'efficient': 2,\n",
       " 'solve': 1,\n",
       " 'math': 2,\n",
       " 'various': 1,\n",
       " 'real': 3,\n",
       " 'organized': 2,\n",
       " 'maybe': 1,\n",
       " 'show': 4,\n",
       " 'top': 3,\n",
       " 'letter': 1,\n",
       " 'expand': 1,\n",
       " 'rest': 2,\n",
       " 'list': 2,\n",
       " 'long': 8,\n",
       " 'pain': 1,\n",
       " 'repeat': 1,\n",
       " 'option': 6,\n",
       " 'sort': 2,\n",
       " 'type': 4,\n",
       " 'meat': 1,\n",
       " 'cheese': 1,\n",
       " '000': 1,\n",
       " 'sitting': 1,\n",
       " '11': 1,\n",
       " '230': 1,\n",
       " 'made': 3,\n",
       " '2': 7,\n",
       " 'brother': 1,\n",
       " 'he': 3,\n",
       " 'friendly': 2,\n",
       " 'system': 5,\n",
       " 'hooked': 1,\n",
       " 'found': 3,\n",
       " 'out': 9,\n",
       " 'unique': 1,\n",
       " 'hair': 1,\n",
       " 'color': 1,\n",
       " 'friend': 2,\n",
       " 'some': 15,\n",
       " 'direct': 1,\n",
       " 'access': 4,\n",
       " 'messenger': 1,\n",
       " 'keyboard': 1,\n",
       " 'awesomely': 1,\n",
       " 'worse': 2,\n",
       " 'close': 2,\n",
       " 'manually': 1,\n",
       " '30min': 1,\n",
       " 'nothing': 4,\n",
       " 'yell': 1,\n",
       " 'continue': 2,\n",
       " 'force': 1,\n",
       " 'restart': 1,\n",
       " 'annoying': 1,\n",
       " 'wont': 4,\n",
       " 'completely': 1,\n",
       " 'decide': 1,\n",
       " 'physical': 1,\n",
       " 'destroy': 1,\n",
       " 'cable': 1,\n",
       " 'tomb': 1,\n",
       " 'mask': 1,\n",
       " 'match': 4,\n",
       " 'few': 2,\n",
       " 'notification': 1,\n",
       " 'said': 3,\n",
       " 'surprise': 1,\n",
       " 'end': 3,\n",
       " 'ended': 2,\n",
       " 'costing': 1,\n",
       " '150': 1,\n",
       " 'require': 2,\n",
       " 'deluxe': 1,\n",
       " 'schedule': 2,\n",
       " '4': 2,\n",
       " 'run': 4,\n",
       " 'child': 3,\n",
       " 'progress': 3,\n",
       " 'daily': 5,\n",
       " 'basis': 1,\n",
       " 'endlessly': 1,\n",
       " 'already': 2,\n",
       " 'garbage': 2,\n",
       " 'tha': 1,\n",
       " 'best': 14,\n",
       " 'house': 1,\n",
       " 'waiting': 3,\n",
       " 'couple': 2,\n",
       " 'mobile': 1,\n",
       " 'bad': 6,\n",
       " 'auto': 2,\n",
       " 'click': 1,\n",
       " 'buttons': 1,\n",
       " 'sound': 2,\n",
       " 'try': 6,\n",
       " 'trial': 4,\n",
       " '100': 2,\n",
       " 'streaming': 3,\n",
       " 'service': 6,\n",
       " 'length': 2,\n",
       " '90': 2,\n",
       " '30': 2,\n",
       " 'fine': 3,\n",
       " 'since': 5,\n",
       " 'last': 3,\n",
       " 'let': 5,\n",
       " 'reset': 2,\n",
       " 'd': 1,\n",
       " 'upcoming': 1,\n",
       " 'trip': 1,\n",
       " 'week': 2,\n",
       " 'understand': 1,\n",
       " 'literally': 3,\n",
       " 'quality': 2,\n",
       " 'home': 2,\n",
       " 'messy': 1,\n",
       " 'store': 1,\n",
       " 'reason': 4,\n",
       " 'variety': 1,\n",
       " 'different': 1,\n",
       " 'locate': 1,\n",
       " 'son': 1,\n",
       " 'sometimes': 4,\n",
       " 'someone': 2,\n",
       " '30sec': 1,\n",
       " 'advertise': 1,\n",
       " 'interfere': 1,\n",
       " 'patience': 1,\n",
       " 'bite': 1,\n",
       " 'size': 1,\n",
       " 'worthless': 1,\n",
       " 'doing': 3,\n",
       " 'little': 6,\n",
       " 'minute': 1,\n",
       " 'refresh': 1,\n",
       " 'receipts': 2,\n",
       " 'kept': 2,\n",
       " 'save': 1,\n",
       " 'receipt': 1,\n",
       " 'prepare': 1,\n",
       " 'lab': 1,\n",
       " 'rat': 1,\n",
       " 'crucial': 1,\n",
       " 'missing': 1,\n",
       " 'summer': 1,\n",
       " 'outlander': 1,\n",
       " 'favorite': 3,\n",
       " 'series': 2,\n",
       " 'advice': 1,\n",
       " 'karma': 5,\n",
       " 'raise': 1,\n",
       " 'score': 2,\n",
       " 'considerably': 1,\n",
       " 'bank': 3,\n",
       " 'listed': 2,\n",
       " 'link': 3,\n",
       " 'accept': 2,\n",
       " 'name': 2,\n",
       " 'saying': 1,\n",
       " 'invalid': 1,\n",
       " 'constantly': 2,\n",
       " 'glory': 1,\n",
       " 'trying': 3,\n",
       " 'point': 2,\n",
       " 'granddaughter': 1,\n",
       " 'teacher': 1,\n",
       " 'another': 2,\n",
       " 'longer': 2,\n",
       " 'text': 1,\n",
       " 'wherever': 1,\n",
       " 'calm': 3,\n",
       " 'peacefully': 1,\n",
       " 'fear': 1,\n",
       " 'downside': 2,\n",
       " 'exit': 1,\n",
       " 'mood': 1,\n",
       " 'white': 1,\n",
       " 'device': 1,\n",
       " 'video': 2,\n",
       " '720p': 1,\n",
       " '1080p': 1,\n",
       " 'load': 4,\n",
       " 'original': 2,\n",
       " 'channel': 2,\n",
       " 'ur': 1,\n",
       " 'mirror': 1,\n",
       " 'jitters': 1,\n",
       " 'intuitive': 1,\n",
       " 'tag': 1,\n",
       " 'accurate': 2,\n",
       " 'actual': 1,\n",
       " 'faster': 2,\n",
       " 'hey': 1,\n",
       " 'today': 2,\n",
       " '1st': 2,\n",
       " 'active': 1,\n",
       " 'into': 2,\n",
       " 'allow': 2,\n",
       " 'us': 1,\n",
       " 'pick': 3,\n",
       " 'feel': 1,\n",
       " 'overall': 1,\n",
       " 'almost': 2,\n",
       " 'supposed': 1,\n",
       " 'clothes': 1,\n",
       " 'whenever': 1,\n",
       " 'chat': 1,\n",
       " 'becomes': 1,\n",
       " 'people': 6,\n",
       " 'who': 4,\n",
       " 'reading': 1,\n",
       " 'spending': 1,\n",
       " 'touch': 2,\n",
       " 'whats': 2,\n",
       " 'happening': 1,\n",
       " 'academic': 1,\n",
       " 'knowing': 1,\n",
       " 'general': 1,\n",
       " 'lost': 3,\n",
       " 'searching': 1,\n",
       " 'logged': 1,\n",
       " 'login': 1,\n",
       " 'incorrect': 1,\n",
       " 'wrong': 3,\n",
       " 'lots': 3,\n",
       " 'communication': 1,\n",
       " 'remind': 1,\n",
       " 'buy': 1,\n",
       " 'soon': 1,\n",
       " 'due': 2,\n",
       " 'graphics': 1,\n",
       " 'recommend': 1,\n",
       " 'l': 1,\n",
       " 'wait': 1,\n",
       " 'days': 2,\n",
       " 'bring': 1,\n",
       " 'gravity': 1,\n",
       " 'until': 1,\n",
       " 'randomly': 1,\n",
       " 'stopping': 1,\n",
       " 'apparent': 1,\n",
       " 'particularly': 1,\n",
       " 'via': 1,\n",
       " 'car': 2,\n",
       " 'violence': 1,\n",
       " 'gun': 1,\n",
       " 'call': 2,\n",
       " 'duty': 1,\n",
       " 'black': 1,\n",
       " 'cod': 1,\n",
       " 'full': 1,\n",
       " 'create': 1,\n",
       " 'progamingmaster32': 1,\n",
       " 'honest': 2,\n",
       " 'en': 1,\n",
       " 'c': 1,\n",
       " 'pour': 1,\n",
       " 'sports': 1,\n",
       " 'horrible': 2,\n",
       " 'bunch': 1,\n",
       " 'fit': 2,\n",
       " 'worked': 1,\n",
       " 'wouldnt': 1,\n",
       " 'pic': 1,\n",
       " 'w2s': 1,\n",
       " 'q': 1,\n",
       " 'interesting': 4,\n",
       " 'hidden': 1,\n",
       " 'essentially': 1,\n",
       " 'scratch': 1,\n",
       " 'opt': 1,\n",
       " 'finally': 2,\n",
       " 'ready': 1,\n",
       " 'over': 8,\n",
       " '140': 1,\n",
       " 'worth': 1,\n",
       " 'were': 1,\n",
       " 'disclosed': 1,\n",
       " 'incredibly': 1,\n",
       " 'wonderful': 2,\n",
       " 'tool': 2,\n",
       " 'keeping': 2,\n",
       " 'family': 4,\n",
       " 'jenny': 1,\n",
       " 'hell': 1,\n",
       " 'enough': 1,\n",
       " 'data': 1,\n",
       " 'cash': 2,\n",
       " 'lifetime': 1,\n",
       " 'pesky': 1,\n",
       " 'liking': 1,\n",
       " 'mostly': 2,\n",
       " 'rack': 1,\n",
       " 'usually': 1,\n",
       " 'shame': 2,\n",
       " 'medication': 1,\n",
       " 'set': 1,\n",
       " 'unable': 1,\n",
       " 'frankly': 1,\n",
       " 'gave': 1,\n",
       " 'instrumental': 1,\n",
       " 'loop': 1,\n",
       " 'sleep': 2,\n",
       " 'team': 2,\n",
       " 'happiest': 1,\n",
       " '911': 1,\n",
       " 'send': 2,\n",
       " 'refund': 2,\n",
       " 'kind': 2,\n",
       " 'stressful': 1,\n",
       " 'win': 2,\n",
       " 'ridiculous': 1,\n",
       " 'indeed': 1,\n",
       " 'prime': 2,\n",
       " 'goodness': 1,\n",
       " 'communicate': 2,\n",
       " 'film': 1,\n",
       " 'banking': 1,\n",
       " 'fact': 2,\n",
       " 'sight': 1,\n",
       " 'hearing': 1,\n",
       " 'along': 1,\n",
       " 'writing': 1,\n",
       " 'repetition': 1,\n",
       " 'finished': 1,\n",
       " 'yet': 1,\n",
       " 'tri': 1,\n",
       " 'ma': 1,\n",
       " 'de': 1,\n",
       " 'lunn': 1,\n",
       " 'leave': 1,\n",
       " 'f': 1,\n",
       " 'debit': 3,\n",
       " 'decided': 1,\n",
       " 'excited': 1,\n",
       " 'being': 1,\n",
       " 'fire': 2,\n",
       " 'haven': 1,\n",
       " 'while': 4,\n",
       " 'shopping': 1,\n",
       " 'background': 1,\n",
       " 'exercise': 1,\n",
       " 'energy': 1,\n",
       " 'bother': 2,\n",
       " 'beat': 1,\n",
       " 'grew': 1,\n",
       " 'enjoy': 4,\n",
       " 'balance': 2,\n",
       " 'upon': 1,\n",
       " 'entering': 1,\n",
       " 'retrieve': 1,\n",
       " 'fingerprint': 1,\n",
       " 'sign': 1,\n",
       " 'character': 1,\n",
       " 'gear': 2,\n",
       " 'humanity': 1,\n",
       " 'planet': 1,\n",
       " 'worried': 1,\n",
       " '6': 2,\n",
       " '7': 1,\n",
       " 'guy': 1,\n",
       " 'negative': 2,\n",
       " 'feeling': 1,\n",
       " 'irritating': 1,\n",
       " 'harder': 1,\n",
       " 'past': 2,\n",
       " 'initial': 1,\n",
       " 'moving': 1,\n",
       " 'watching': 1,\n",
       " 'across': 1,\n",
       " 'public': 1,\n",
       " 'tho': 1,\n",
       " 'n': 1,\n",
       " 'used': 2,\n",
       " 'review': 1,\n",
       " 'become': 1,\n",
       " 'whole': 1,\n",
       " 'price': 2,\n",
       " 'taste': 1,\n",
       " 'yo': 1,\n",
       " 'similar': 1,\n",
       " 'lower': 1,\n",
       " 'library': 1,\n",
       " 'perfectly': 1,\n",
       " 'huh': 1,\n",
       " 'turn': 2,\n",
       " 'title': 1,\n",
       " 'motivate': 1,\n",
       " 'walk': 1,\n",
       " 'honestly': 2,\n",
       " 'why': 3,\n",
       " 'interrupting': 1,\n",
       " 'mail': 1,\n",
       " '1980': 1,\n",
       " 'note': 1,\n",
       " 'safe': 1,\n",
       " 'instantaneous': 1,\n",
       " 'receive': 1,\n",
       " 'funds': 1,\n",
       " 'sent': 2,\n",
       " 'received': 1,\n",
       " 'party': 1,\n",
       " 'memorization': 1,\n",
       " 'information': 2,\n",
       " 'manner': 1,\n",
       " 'watch': 2,\n",
       " 'advertising': 2,\n",
       " 'section': 1,\n",
       " 'piece': 1,\n",
       " 'overseas': 1,\n",
       " 'handy': 1,\n",
       " 'anime': 1,\n",
       " 'selection': 1,\n",
       " 'regret': 1,\n",
       " 'genre': 1,\n",
       " 'officially': 1,\n",
       " 'complaint': 1,\n",
       " 'search': 1,\n",
       " 'beginning': 1,\n",
       " 'aa': 1,\n",
       " 'basement': 1,\n",
       " 'short': 1,\n",
       " 'movie': 1,\n",
       " 'consistently': 1,\n",
       " 'failing': 1,\n",
       " 'disable': 1,\n",
       " 'saving': 2,\n",
       " 'mode': 1,\n",
       " 'known': 1,\n",
       " 'rooted': 1,\n",
       " 'disgusting': 1,\n",
       " 'widespread': 1,\n",
       " 'develop': 1,\n",
       " 'unusable': 1,\n",
       " 'solution': 1,\n",
       " 'customer': 1,\n",
       " 'blamed': 1,\n",
       " 'carrier': 2,\n",
       " 'intact': 1,\n",
       " 'record': 1,\n",
       " 'mi': 1,\n",
       " 'familia': 1,\n",
       " 'el': 1,\n",
       " 'workout': 1,\n",
       " 'unprofessional': 1,\n",
       " 'plain': 1,\n",
       " 'suggesting': 1,\n",
       " 'difference': 1,\n",
       " 'necessity': 1,\n",
       " 'everyone': 1,\n",
       " 'seen': 1,\n",
       " 'join': 1,\n",
       " 'p': 1,\n",
       " 'bug': 2,\n",
       " 'sync': 1,\n",
       " 'amount': 2,\n",
       " 'spent': 1,\n",
       " 'fresh': 1,\n",
       " 'reminder': 1,\n",
       " 'sedentary': 1,\n",
       " 'subway': 1,\n",
       " 'greedy': 1,\n",
       " 'toy': 1,\n",
       " 'grab': 1,\n",
       " 'scam': 1,\n",
       " 'thinking': 1,\n",
       " '45': 1,\n",
       " 'monthly': 2,\n",
       " 'subscription': 2,\n",
       " 'looking': 2,\n",
       " 'clean': 1,\n",
       " 'must': 2,\n",
       " '500': 1,\n",
       " 'generally': 1,\n",
       " 'hanging': 1,\n",
       " 'obviously': 1,\n",
       " 'exclusive': 1,\n",
       " 'disappointed': 2,\n",
       " 'taking': 1,\n",
       " 'improvement': 1,\n",
       " 'apart': 1,\n",
       " 'anxiety': 1,\n",
       " 'course': 1,\n",
       " 'walking': 1,\n",
       " 'latest': 2,\n",
       " 'reasonable': 1,\n",
       " 'bought': 1,\n",
       " 'billed': 1,\n",
       " 'annually': 1,\n",
       " 'contents': 1,\n",
       " 'present': 1,\n",
       " 'our': 1,\n",
       " 'teens': 1,\n",
       " 'yes': 1,\n",
       " 'intentional': 1,\n",
       " 'virus': 1,\n",
       " 'consent': 1,\n",
       " 'probably': 1,\n",
       " 'accidentally': 1,\n",
       " 'hit': 1,\n",
       " 'button': 1,\n",
       " 'ago': 1,\n",
       " 'stopped': 2,\n",
       " 'counting': 1,\n",
       " '4pm': 1,\n",
       " 'y': 1,\n",
       " 'pu': 1,\n",
       " 'unhelpful': 1,\n",
       " 'computer': 1,\n",
       " 'site': 1,\n",
       " 'preferred': 1,\n",
       " 'nese': 1,\n",
       " 'believe': 1,\n",
       " 'truth': 1,\n",
       " 'remove': 1,\n",
       " 'repetitive': 1,\n",
       " 'caloric': 1,\n",
       " 'intake': 1,\n",
       " 'creat': 1,\n",
       " 'taken': 1,\n",
       " 'asset': 1,\n",
       " 'particular': 1,\n",
       " 'frequent': 1,\n",
       " 'gotten': 1,\n",
       " 'poor': 1,\n",
       " 'area': 1,\n",
       " 'kill': 1,\n",
       " 'school': 1,\n",
       " 'her': 1,\n",
       " 'marking': 1,\n",
       " 'beautiful': 1,\n",
       " 'between': 1,\n",
       " 'success': 1,\n",
       " '40': 1,\n",
       " 'losing': 1,\n",
       " 'goal': 1,\n",
       " 'everyday': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count = {} \n",
    "for data in df['bow'].str.lower(): \n",
    "    words = nltk.word_tokenize(data) \n",
    "    for word in words: \n",
    "        if word not in word2count.keys(): \n",
    "            word2count[word] = 1\n",
    "        else: \n",
    "            word2count[word] += 1\n",
    "word2count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import *\n",
    "\n",
    "rvws = pd.read_csv('Dataset3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize review then tag each word using nltk's `pos_tag` function\n",
    "\n",
    "def get_tags(x):\n",
    "    tense = []\n",
    "    only = []\n",
    "    word = word_tokenize(x)\n",
    "    tense.append(pos_tag(word))\n",
    "    \n",
    "    for t in tense:\n",
    "        for i in t:\n",
    "            only.append(i[1])\n",
    "    return only\n",
    "\n",
    "df['tag'] = df['processed_text'].map(lambda x: get_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to read each tag and identify how many words are future, past, or present tense\n",
    "\n",
    "def future(x):\n",
    "    future_tense = []\n",
    "    for i in x:\n",
    "        if i == \"MD\":\n",
    "            future_tense.append(i)\n",
    "            \n",
    "    return len(future_tense)\n",
    "            \n",
    "\n",
    "def present_simp(x):\n",
    "    present_tense = []\n",
    "    for i in x:\n",
    "        if i in [\"VBP\", \"VBZ\",\"VBG\"]:\n",
    "            present_tense.append(i)\n",
    "        \n",
    "    return len(present_tense)\n",
    "\n",
    "\n",
    "def present_con(x):\n",
    "    present_tense = []\n",
    "    for i in x:\n",
    "        if i.lower() in [\"could\", \"would\",\"should\", \"couldn't\", \"wouldn't\", \"shouldn't\"] and [\"if\"]:\n",
    "            present_tense.append(i)\n",
    "        \n",
    "    return len(present_tense)\n",
    "\n",
    "\n",
    "def past(x):\n",
    "    past_tense = []\n",
    "    for i in x:\n",
    "        if i in [\"VBD\", \"VBN\"]:\n",
    "            past_tense.append(i)\n",
    "        \n",
    "    return len(past_tense)\n",
    "\n",
    "\n",
    "    \n",
    "df['future'] = df.tag.map(lambda x: future(x))\n",
    "df['present_simple'] = df.tag.map(lambda x: present_simp(x))\n",
    "df['present_con'] = df.processed_text.map(lambda x: present_con(x))\n",
    "df['past'] = df.tag.map(lambda x: past(x))\n",
    "\n",
    "df.to_csv('dataset3_with_nlp_techniques.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
