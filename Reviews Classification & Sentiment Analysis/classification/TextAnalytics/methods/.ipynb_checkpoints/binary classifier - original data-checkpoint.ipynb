{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier - unprocessed text\n",
    "`sklearn GaussianNB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classifier modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "\n",
    "# import other modules\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge our labelled dataset with original unprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = pd.read_excel('data/FinalProcessed.xlsx')\n",
    "reviewed = pd.read_csv('data/dataset3_with_nlp_techniques.csv')\n",
    "labels = pd.read_csv('data/labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appTitle_x</th>\n",
       "      <th>userName_x</th>\n",
       "      <th>date_x</th>\n",
       "      <th>score_x</th>\n",
       "      <th>text</th>\n",
       "      <th>Category_x</th>\n",
       "      <th>date_ex_x</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordcount_x</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>...</th>\n",
       "      <th>tag</th>\n",
       "      <th>future</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>present_con</th>\n",
       "      <th>past</th>\n",
       "      <th>Rating</th>\n",
       "      <th>User Experience</th>\n",
       "      <th>Bug Report</th>\n",
       "      <th>Feature Report</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Photomath</td>\n",
       "      <td>Nasir Ford</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>5</td>\n",
       "      <td>this app is amazing</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>339</td>\n",
       "      <td>...</td>\n",
       "      <td>['DT', 'VBZ', 'VBG']</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Quizlet: Learn Languages &amp; Vocab with Flashcards</td>\n",
       "      <td>Emily Lillian</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>5</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>339</td>\n",
       "      <td>...</td>\n",
       "      <td>['DT', 'VBZ', 'VBG']</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Duolingo: Learn Languages Free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>5</td>\n",
       "      <td>this app is amazing</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>339</td>\n",
       "      <td>...</td>\n",
       "      <td>['DT', 'VBZ', 'VBG']</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Google Classroom</td>\n",
       "      <td>SULTAN ABDUL KADER ISMAIL</td>\n",
       "      <td>2019-03-02</td>\n",
       "      <td>5</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>339</td>\n",
       "      <td>...</td>\n",
       "      <td>['DT', 'VBZ', 'VBG']</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Photomath</td>\n",
       "      <td>father of father</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>5</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>339</td>\n",
       "      <td>...</td>\n",
       "      <td>['DT', 'VBZ', 'VBG']</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172444</td>\n",
       "      <td>Samsung Health</td>\n",
       "      <td>HINDURAM SOY</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>5</td>\n",
       "      <td>A very useful version appeared on, I liked it.</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>A very useful version on  I it</td>\n",
       "      <td>7.0</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>['DT', 'RB', 'JJ', 'NN', 'IN', 'PRP', 'PRP']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172445</td>\n",
       "      <td>Calorie Counter - MyFitnessPal</td>\n",
       "      <td>Matthew Sleeman</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>helps track calorie and also once diary comple...</td>\n",
       "      <td>HEALTH_AND_FITNESS</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>track calorie and also once diary how much you...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>['NN', 'NN', 'CC', 'RB', 'RB', 'JJ', 'WRB', 'R...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UserExperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172446</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>Ken Samic</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>1</td>\n",
       "      <td>So I had a problem upon entering the app and I...</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>So I had a problem upon entering the and I can...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>279</td>\n",
       "      <td>...</td>\n",
       "      <td>['RB', 'PRP', 'VBD', 'DT', 'NN', 'IN', 'VBG', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172447</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>Brendan Fernandes</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>honestly I'm not bad, but something must be up...</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>honestly I  m not bad  but something must be u...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>['RB', 'PRP', 'MD', 'RB', 'JJ', 'CC', 'NN', 'M...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UserExperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172448</td>\n",
       "      <td>Amazon Music</td>\n",
       "      <td>Peter Murray</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Dropped Sirius/XM and this is far easier and c...</td>\n",
       "      <td>MUSIC_AND_AUDIO</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>and this is far easier and</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>['CC', 'DT', 'VBZ', 'RB', 'JJR', 'CC']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172449 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              appTitle_x  \\\n",
       "0                                              Photomath   \n",
       "1       Quizlet: Learn Languages & Vocab with Flashcards   \n",
       "2                         Duolingo: Learn Languages Free   \n",
       "3                                       Google Classroom   \n",
       "4                                              Photomath   \n",
       "...                                                  ...   \n",
       "172444                                    Samsung Health   \n",
       "172445                    Calorie Counter - MyFitnessPal   \n",
       "172446                                            Tinder   \n",
       "172447                                            Tinder   \n",
       "172448                                      Amazon Music   \n",
       "\n",
       "                       userName_x     date_x  score_x  \\\n",
       "0                      Nasir Ford 2019-03-07        5   \n",
       "1                   Emily Lillian 2019-01-23        5   \n",
       "2                             NaN 2019-03-06        5   \n",
       "3       SULTAN ABDUL KADER ISMAIL 2019-03-02        5   \n",
       "4                father of father 2019-02-14        5   \n",
       "...                           ...        ...      ...   \n",
       "172444               HINDURAM SOY 2019-04-13        5   \n",
       "172445            Matthew Sleeman 2019-04-10        5   \n",
       "172446                  Ken Samic 2019-04-13        1   \n",
       "172447          Brendan Fernandes 2019-04-10        1   \n",
       "172448               Peter Murray 2019-04-10        5   \n",
       "\n",
       "                                                     text          Category_x  \\\n",
       "0                                     this app is amazing           EDUCATION   \n",
       "1                                         this is amazing           EDUCATION   \n",
       "2                                     this app is amazing           EDUCATION   \n",
       "3                                         this is amazing           EDUCATION   \n",
       "4                                         this is amazing           EDUCATION   \n",
       "...                                                   ...                 ...   \n",
       "172444     A very useful version appeared on, I liked it.  HEALTH_AND_FITNESS   \n",
       "172445  helps track calorie and also once diary comple...  HEALTH_AND_FITNESS   \n",
       "172446  So I had a problem upon entering the app and I...           LIFESTYLE   \n",
       "172447  honestly I'm not bad, but something must be up...           LIFESTYLE   \n",
       "172448  Dropped Sirius/XM and this is far easier and c...     MUSIC_AND_AUDIO   \n",
       "\n",
       "        date_ex_x                                     processed_text  \\\n",
       "0      2019-03-08                                    this is amazing   \n",
       "1      2019-03-08                                    this is amazing   \n",
       "2      2019-03-08                                    this is amazing   \n",
       "3      2019-03-08                                    this is amazing   \n",
       "4      2019-03-08                                    this is amazing   \n",
       "...           ...                                                ...   \n",
       "172444 2019-04-14                    A very useful version on  I it    \n",
       "172445 2019-04-14  track calorie and also once diary how much you...   \n",
       "172446 2019-04-14  So I had a problem upon entering the and I can...   \n",
       "172447 2019-04-14  honestly I  m not bad  but something must be u...   \n",
       "172448 2019-04-14                        and this is far easier and    \n",
       "\n",
       "        wordcount_x  Unnamed: 0  ...  \\\n",
       "0               3.0         339  ...   \n",
       "1               3.0         339  ...   \n",
       "2               3.0         339  ...   \n",
       "3               3.0         339  ...   \n",
       "4               3.0         339  ...   \n",
       "...             ...         ...  ...   \n",
       "172444          7.0         171  ...   \n",
       "172445         11.0          38  ...   \n",
       "172446         32.0         279  ...   \n",
       "172447         68.0         345  ...   \n",
       "172448          6.0          28  ...   \n",
       "\n",
       "                                                      tag future  \\\n",
       "0                                    ['DT', 'VBZ', 'VBG']      0   \n",
       "1                                    ['DT', 'VBZ', 'VBG']      0   \n",
       "2                                    ['DT', 'VBZ', 'VBG']      0   \n",
       "3                                    ['DT', 'VBZ', 'VBG']      0   \n",
       "4                                    ['DT', 'VBZ', 'VBG']      0   \n",
       "...                                                   ...    ...   \n",
       "172444       ['DT', 'RB', 'JJ', 'NN', 'IN', 'PRP', 'PRP']      0   \n",
       "172445  ['NN', 'NN', 'CC', 'RB', 'RB', 'JJ', 'WRB', 'R...      1   \n",
       "172446  ['RB', 'PRP', 'VBD', 'DT', 'NN', 'IN', 'VBG', ...      1   \n",
       "172447  ['RB', 'PRP', 'MD', 'RB', 'JJ', 'CC', 'NN', 'M...      2   \n",
       "172448             ['CC', 'DT', 'VBZ', 'RB', 'JJR', 'CC']      0   \n",
       "\n",
       "       present_simple  present_con past Rating  User Experience Bug Report  \\\n",
       "0                   2            0    0      1                0          0   \n",
       "1                   2            0    0      1                0          0   \n",
       "2                   2            0    0      1                0          0   \n",
       "3                   2            0    0      1                0          0   \n",
       "4                   2            0    0      1                0          0   \n",
       "...               ...          ...  ...    ...              ...        ...   \n",
       "172444              0            0    0      1                0          0   \n",
       "172445              0            0    0      0                1          0   \n",
       "172446              1            0    3      0                0          1   \n",
       "172447             10            0    1      0                1          0   \n",
       "172448              1            0    0      1                0          0   \n",
       "\n",
       "       Feature Report           label  \n",
       "0                   0          Rating  \n",
       "1                   0          Rating  \n",
       "2                   0          Rating  \n",
       "3                   0          Rating  \n",
       "4                   0          Rating  \n",
       "...               ...             ...  \n",
       "172444              0          Rating  \n",
       "172445              0  UserExperience  \n",
       "172446              0             Bug  \n",
       "172447              0  UserExperience  \n",
       "172448              0          Rating  \n",
       "\n",
       "[172449 rows x 32 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig.merge(reviewed, how=\"inner\", on = 'processed_text') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Repeat for Bug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/REJ_data/Bug_tt.json', encoding='utf-8-sig') as json_file:\n",
    "    train = json.load(json_file)\n",
    "    \n",
    "BUG = pd.DataFrame.from_dict(json_normalize(train), orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bow of test data\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer = TfidfVectorizer(use_idf = True)\n",
    "\n",
    "x = vectorizer.fit_transform(BUG.comment).toarray()\n",
    "y = BUG.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "\n",
    "# predict on test data\n",
    "def binary_class(x):\n",
    "    p = vectorizer.transform([x]).toarray()\n",
    "    return g.predict(p)\n",
    "    \n",
    "\n",
    "bug_pred = pd.DataFrame({'review' : df.text[0:384], 'label' : labels.label})\n",
    "bug_pred['tf-idf'] = df.text.map(lambda x: binary_class(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on stop words removal\n",
    "x = vectorizer.fit_transform(BUG.stopwords_removal).toarray()\n",
    "y = BUG.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "def binary_class2(x):\n",
    "    p = vectorizer.transform(x).toarray()\n",
    "    return g.predict(p)\n",
    "\n",
    "# make our stopwords col full sentence\n",
    "df.stopword = df.stopword.map(lambda x: ' '.join(x))\n",
    "\n",
    "# predict\n",
    "bug_pred['tf-idf-stopwords'] = df.stopword.map(lambda x: binary_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on lemmatized removal\n",
    "x = vectorizer.fit_transform(BUG.lemmatized_comment).toarray()\n",
    "y = BUG.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "# make our lemmatizer col full sentence\n",
    "df.lemmatizer = df.lemmatizer.map(lambda x: ' '.join(x))\n",
    "\n",
    "# predict\n",
    "bug_pred['tf-idf+lemmatizer'] = df.lemmatizer.map(lambda x: binary_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on lemmatized removal\n",
    "x = vectorizer.fit_transform(BUG.lemmatized_comment).toarray()\n",
    "y = BUG.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "# make our lemmatizer col full sentence\n",
    "df.lemmatizer = df.lemmatizer.map(lambda x: ' '.join(x))\n",
    "\n",
    "# predict\n",
    "bug_pred['tf-idf+lemmatizer'] = df.lemmatizer.map(lambda x: binary_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>tf-idf-stopwords</th>\n",
       "      <th>tf-idf+lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>this app is amazing</td>\n",
       "      <td>Rating</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>this app is amazing</td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>Rating</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>this is amazing</td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>i love it</td>\n",
       "      <td>Rating</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>i love it</td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>i love it</td>\n",
       "      <td>Rating</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>i love it</td>\n",
       "      <td>Rating</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>i love it</td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "      <td>Not_Bug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  review           label   tf-idf tf-idf-stopwords  \\\n",
       "0    this app is amazing          Rating  Not_Bug          Not_Bug   \n",
       "1        this is amazing  UserExperience  Not_Bug          Not_Bug   \n",
       "2    this app is amazing  UserExperience  Not_Bug          Not_Bug   \n",
       "3        this is amazing          Rating  Not_Bug          Not_Bug   \n",
       "4        this is amazing  UserExperience  Not_Bug          Not_Bug   \n",
       "..                   ...             ...      ...              ...   \n",
       "379            i love it          Rating  Not_Bug          Not_Bug   \n",
       "380            i love it  UserExperience  Not_Bug          Not_Bug   \n",
       "381            i love it          Rating  Not_Bug          Not_Bug   \n",
       "382            i love it          Rating  Not_Bug          Not_Bug   \n",
       "383            i love it  UserExperience  Not_Bug          Not_Bug   \n",
       "\n",
       "    tf-idf+lemmatizer  \n",
       "0             Not_Bug  \n",
       "1             Not_Bug  \n",
       "2             Not_Bug  \n",
       "3             Not_Bug  \n",
       "4             Not_Bug  \n",
       "..                ...  \n",
       "379           Not_Bug  \n",
       "380           Not_Bug  \n",
       "381           Not_Bug  \n",
       "382           Not_Bug  \n",
       "383           Not_Bug  \n",
       "\n",
       "[384 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_pred['tf-idf'] = bug_pred['tf-idf'].apply(''.join)\n",
    "bug_pred['tf-idf+lemmatizer'] = bug_pred['tf-idf+lemmatizer'].apply(''.join)\n",
    "bug_pred['tf-idf-stopwords'] = bug_pred['tf-idf-stopwords'].apply(''.join)\n",
    "bug_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>tf-idf-stopwords</th>\n",
       "      <th>tf-idf+lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review, label, tf-idf, tf-idf-stopwords, tf-idf+lemmatizer]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_pred.loc[bug_pred['tf-idf'] == 'Bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technique</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tf-idf-stopwords</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tf-idf+lemmatization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              technique  precision  recall               f1_score\n",
       "0                tf-idf        0.0     0.0  (0.0, 0.0, 0.0, None)\n",
       "1      tf-idf-stopwords        0.0     0.0  (0.0, 0.0, 0.0, None)\n",
       "2  tf-idf+lemmatization        0.0     0.0                    NaN"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "y_true = bug_pred.label\n",
    "y_pred = bug_pred['tf-idf']\n",
    "\n",
    "# tf-idf\n",
    "prec = precision_score(y_true, y_pred, average = \"micro\")\n",
    "recall = recall_score(y_true, y_pred, average = \"micro\")\n",
    "f = precision_recall_fscore_support(y_true, y_pred, average = \"micro\")\n",
    "\n",
    "# tf-idf-stopwords\n",
    "y_pred = bug_pred['tf-idf-stopwords']\n",
    "\n",
    "prec2 = precision_score(y_true, y_pred, average = \"micro\")\n",
    "recall2 = recall_score(y_true, y_pred, average = \"micro\")\n",
    "f2 = precision_recall_fscore_support(y_true, y_pred, average = \"micro\")\n",
    "\n",
    "\n",
    "# tf-idf+lemma\n",
    "y_pred = bug_pred['tf-idf+lemmatizer']\n",
    "\n",
    "prec3 = precision_score(y_true, y_pred, average = \"micro\")\n",
    "recall3 = recall_score(y_true, y_pred, average = \"micro\")\n",
    "f3 = 2*(prec3*recall3)/(prec3+recall3)\n",
    "\n",
    "\n",
    "pd.DataFrame({'technique' : ['tf-idf', 'tf-idf-stopwords', 'tf-idf+lemmatization'], \n",
    "              'precision' : [prec, prec2, prec3],\n",
    "            'recall' : [recall, recall2, recall3],\n",
    "             'f1_score' : [f, f2, f3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Repeat for Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/REJ_data/Feature_tt.json', encoding='utf-8-sig') as json_file:\n",
    "    train = json.load(json_file)\n",
    "    \n",
    "FEAT = pd.DataFrame.from_dict(json_normalize(train), orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bow of test data\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer = TfidfVectorizer(use_idf = True)\n",
    "\n",
    "x = vectorizer.fit_transform(FEAT.comment).toarray()\n",
    "y = FEAT.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "\n",
    "# predict on test data\n",
    "def binary_class(x):\n",
    "    p = vectorizer.transform([x]).toarray()\n",
    "    return g.predict(p)\n",
    "    \n",
    "\n",
    "feat_pred = pd.DataFrame({'review' : df.text[0:384], 'label' : labels.label})\n",
    "feat_pred['tf-idf'] = df.text.map(lambda x: binary_class(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on stop words removal\n",
    "x = vectorizer.fit_transform(FEAT.stopwords_removal).toarray()\n",
    "y = FEAT.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "def binary_class2(x):\n",
    "    p = vectorizer.transform(x).toarray()\n",
    "    return g.predict(p)\n",
    "\n",
    "# make our stopwords col full sentence\n",
    "df.stopword = df.stopword.map(lambda x: ' '.join(x))\n",
    "\n",
    "# predict\n",
    "feat_pred['tf-idf-stopwords'] = df.stopword.map(lambda x: binary_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on lemmatized removal\n",
    "x = vectorizer.fit_transform(FEAT.lemmatized_comment).toarray()\n",
    "y = FEAT.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "# make our lemmatizer col full sentence\n",
    "df.lemmatizer = df.lemmatizer.map(lambda x: ' '.join(x))\n",
    "\n",
    "# predict\n",
    "feat_pred['tf-idf+lemmatizer'] = df.lemmatizer.map(lambda x: binary_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on lemmatized removal\n",
    "x = vectorizer.fit_transform(FEAT.lemmatized_comment).toarray()\n",
    "y = FEAT.label\n",
    "\n",
    "# train the classifier\n",
    "g = GaussianNB()  \n",
    "g = g.fit(x, y)  \n",
    "\n",
    "# make our lemmatizer col full sentence\n",
    "df.lemmatizer = df.lemmatizer.map(lambda x: ' '.join(x))\n",
    "\n",
    "# predict\n",
    "feat_pred['tf-idf+lemmatizer'] = df.lemmatizer.map(lambda x: binary_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_pred['tf-idf'] = feat_pred['tf-idf'].apply(''.join)\n",
    "feat_pred['tf-idf+lemmatizer'] = feat_pred['tf-idf+lemmatizer'].apply(''.join)\n",
    "feat_pred['tf-idf-stopwords'] = feat_pred['tf-idf-stopwords'].apply(''.join)\n",
    "feat_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "y_true = feat_pred.label\n",
    "y_pred = feat_pred['tf-idf']\n",
    "\n",
    "# tf-idf\n",
    "prec = precision_score(y_true, y_pred, average = \"micro\")\n",
    "recall = recall_score(y_true, y_pred, average = \"micro\")\n",
    "f = precision_recall_fscore_support(y_true, y_pred, average = \"micro\")\n",
    "\n",
    "# tf-idf-stopwords\n",
    "y_pred = feat_pred['tf-idf-stopwords']\n",
    "\n",
    "prec2 = precision_score(y_true, y_pred, average = \"micro\")\n",
    "recall2 = recall_score(y_true, y_pred, average = \"micro\")\n",
    "f2 = precision_recall_fscore_support(y_true, y_pred, average = \"micro\")\n",
    "\n",
    "\n",
    "# tf-idf+lemma\n",
    "y_pred = feat_pred['tf-idf+lemmatizer']\n",
    "\n",
    "prec3 = precision_score(y_true, y_pred, average = \"micro\")\n",
    "recall3 = recall_score(y_true, y_pred, average = \"micro\")\n",
    "f3 = 2*(prec3*recall3)/(prec3+recall3)\n",
    "\n",
    "\n",
    "pd.DataFrame({'technique' : ['tf-idf', 'tf-idf-stopwords', 'tf-idf+lemmatization'], \n",
    "              'precision' : [prec, prec2, prec3],\n",
    "            'recall' : [recall, recall2, recall3],\n",
    "             'f1_score' : [f, f2, f3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
